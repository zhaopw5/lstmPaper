#!/usr/bin/env python3
"""
æ”¹è¿›çš„LSTMè®­ç»ƒè„šæœ¬ - è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜
åŸºäºŽç¬¬ä¸€æ¬¡è®­ç»ƒç»“æžœçš„æ”¹è¿›ç‰ˆæœ¬
"""

import torch
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/phil/Files/lstmPaper_v250618/model')

from data_processor import CosmicRayDataProcessor, split_time_series
from lstm_model import CosmicRayLSTM, ModelTrainer, calculate_metrics

def create_data_loaders(X_train, y_train, X_val, y_val, batch_size=16):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    train_dataset = TensorDataset(X_train, y_train)
    val_dataset = TensorDataset(X_val, y_val)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, val_loader

def plot_predictions_simple(y_true, y_pred, dates, title="Prediction Results", save_path=None):
    """ç®€åŒ–çš„é¢„æµ‹ç»“æžœç»˜å›¾å‡½æ•°"""
    plt.figure(figsize=(15, 8))
    
    # è½¬æ¢æ—¥æœŸ
    date_objects = [datetime.strptime(date, '%Y-%m-%d') for date in dates]
    
    plt.subplot(2, 1, 1)
    plt.plot(date_objects, y_true, label='True Values', alpha=0.7, linewidth=1)
    plt.plot(date_objects, y_pred, label='Predictions', alpha=0.7, linewidth=1)
    plt.xlabel('Date')
    plt.ylabel('Cosmic Ray Flux')
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    
    # æ•£ç‚¹å›¾
    plt.subplot(2, 1, 2)
    plt.scatter(y_true, y_pred, alpha=0.6)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
    plt.xlabel('True Values')
    plt.ylabel('Predictions')
    plt.title('True vs Predicted')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

def main_improved():
    """æ”¹è¿›çš„ä¸»è®­ç»ƒæµç¨‹"""
    print("=== æ”¹è¿›çš„å®‡å®™çº¿LSTMæ¨¡åž‹ ===")
    print("ç›®æ ‡: è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜\n")
    
    # æ•°æ®è·¯å¾„
    solar_data_path = '/home/phil/Files/lstmPaper_v250618/data/solar_physics_data_1980_extend_smoothed.csv'
    cosmic_ray_path = '/home/phil/Files/lstmPaper_v250618/data/raw_data/ams/helium.csv'
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = '/home/phil/Files/lstmPaper_v250618/model/results'
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¹è¿›çš„è¶…å‚æ•°é…ç½®
    config = {
        'sequence_length': 365,
        'hidden_size': 64,        # å‡å°‘å¤æ‚åº¦: 128 â†’ 64
        'num_layers': 1,          # å‡å°‘å±‚æ•°: 2 â†’ 1  
        'dropout': 0.4,           # å¢žåŠ dropout: 0.2 â†’ 0.4
        'batch_size': 16,         # å‡å°‘æ‰¹å¤§å°: 32 â†’ 16
        'epochs': 200,            # å¢žåŠ è®­ç»ƒè½®æ•°: 100 â†’ 200
        'learning_rate': 0.0001,  # é™ä½Žå­¦ä¹ çŽ‡: 0.001 â†’ 0.0001
        'patience': 25,           # å¢žåŠ è€å¿ƒ: 15 â†’ 25
    }
    
    print("æ”¹è¿›é…ç½® (vs åŽŸé…ç½®):")
    original_config = {
        'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2,
        'batch_size': 32, 'epochs': 100, 'learning_rate': 0.001, 'patience': 15
    }
    
    for key in config.keys():
        if key in original_config:
            print(f"  {key}: {original_config[key]} â†’ {config[key]}")
        else:
            print(f"  {key}: {config[key]}")
    print()
    
    # æ­¥éª¤1: æ•°æ®å¤„ç†
    print("æ­¥éª¤1: æ•°æ®å¤„ç†")
    processor = CosmicRayDataProcessor(
        solar_data_path=solar_data_path,
        cosmic_ray_path=cosmic_ray_path,
        sequence_length=config['sequence_length'],
        target_rigidity=2.97
    )
    
    X, y, dates = processor.prepare_data()
    print(f"æ•°æ®å‡†å¤‡å®Œæˆ: {len(X)} ä¸ªæ ·æœ¬\n")
    
    # æ­¥éª¤2: æ•°æ®åˆ†å‰²
    print("æ­¥éª¤2: æ•°æ®åˆ†å‰²")
    (X_train, y_train, dates_train), (X_val, y_val, dates_val), (X_test, y_test, dates_test) = \
        split_time_series(X, y, dates, train_ratio=0.7, val_ratio=0.15)
    print()
    
    # æ­¥éª¤3: åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("æ­¥éª¤3: åˆ›å»ºæ•°æ®åŠ è½½å™¨")
    train_loader, val_loader = create_data_loaders(
        X_train, y_train, X_val, y_val, 
        batch_size=config['batch_size']
    )
    print(f"æ‰¹æ¬¡é…ç½®: è®­ç»ƒ={len(train_loader)}, éªŒè¯={len(val_loader)}\n")
    
    # æ­¥éª¤4: åˆ›å»ºæ”¹è¿›çš„æ¨¡åž‹
    print("æ­¥éª¤4: åˆ›å»ºæ”¹è¿›çš„LSTMæ¨¡åž‹")
    model = CosmicRayLSTM(
        input_size=X.shape[2],
        hidden_size=config['hidden_size'],
        num_layers=config['num_layers'],
        dropout=config['dropout']
    )
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    trainer = ModelTrainer(model, device=device)
    
    print(f"æ¨¡åž‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # æ­¥éª¤5: è®­ç»ƒæ”¹è¿›æ¨¡åž‹
    print("æ­¥éª¤5: å¼€å§‹è®­ç»ƒæ”¹è¿›æ¨¡åž‹")
    model_save_path = os.path.join(output_dir, 'improved_model.pth')
    
    trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=config['epochs'],
        learning_rate=config['learning_rate'],
        patience=config['patience'],
        save_path=model_save_path
    )
    print()
    
    # æ­¥éª¤6: æ¨¡åž‹è¯„ä¼°
    print("æ­¥éª¤6: æ¨¡åž‹è¯„ä¼°")
    
    # åŠ è½½æœ€ä½³æ¨¡åž‹
    checkpoint = torch.load(model_save_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # é¢„æµ‹
    print("æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
    
    # æµ‹è¯•é›†é¢„æµ‹
    y_test_pred = trainer.predict(X_test)
    y_test_true = processor.inverse_transform_y(y_test.numpy())
    y_test_pred = processor.inverse_transform_y(y_test_pred)
    
    # éªŒè¯é›†é¢„æµ‹  
    y_val_pred = trainer.predict(X_val)
    y_val_true = processor.inverse_transform_y(y_val.numpy())
    y_val_pred = processor.inverse_transform_y(y_val_pred)
    
    # è®­ç»ƒé›†é¢„æµ‹
    y_train_pred = trainer.predict(X_train)
    y_train_true = processor.inverse_transform_y(y_train.numpy())
    y_train_pred = processor.inverse_transform_y(y_train_pred)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    print("\n=== æ”¹è¿›æ¨¡åž‹æ€§èƒ½è¯„ä¼° ===")
    
    train_metrics = calculate_metrics(y_train_true, y_train_pred)
    print("è®­ç»ƒé›†æ€§èƒ½:")
    for metric, value in train_metrics.items():
        print(f"  {metric}: {value:.6f}")
    
    val_metrics = calculate_metrics(y_val_true, y_val_pred)
    print("\néªŒè¯é›†æ€§èƒ½:")
    for metric, value in val_metrics.items():
        print(f"  {metric}: {value:.6f}")
    
    test_metrics = calculate_metrics(y_test_true, y_test_pred)
    print("\næµ‹è¯•é›†æ€§èƒ½:")
    for metric, value in test_metrics.items():
        print(f"  {metric}: {value:.6f}")
    
    # æ€§èƒ½æ¯”è¾ƒ
    print("\n=== æ€§èƒ½å¯¹æ¯” (vs åŽŸæ¨¡åž‹) ===")
    print("åŽŸæ¨¡åž‹æµ‹è¯•é›†æ€§èƒ½:")
    print("  RÂ²: -14.083278")
    print("  Correlation: -0.248674") 
    print("  RMSE: 5.406580")
    
    print(f"\næ”¹è¿›æ¨¡åž‹æµ‹è¯•é›†æ€§èƒ½:")
    print(f"  RÂ²: {test_metrics['RÂ²']:.6f}")
    print(f"  Correlation: {test_metrics['Correlation']:.6f}")
    print(f"  RMSE: {test_metrics['RMSE']:.6f}")
    
    # æ”¹è¿›ç¨‹åº¦
    if test_metrics['RÂ²'] > -14.083278:
        print(f"\nâœ… RÂ²æ”¹è¿›: {test_metrics['RÂ²'] - (-14.083278):.6f}")
    if abs(test_metrics['Correlation']) > 0.248674:
        print(f"âœ… ç›¸å…³æ€§æ”¹è¿›: {abs(test_metrics['Correlation']) - 0.248674:.6f}")
    if test_metrics['RMSE'] < 5.406580:
        print(f"âœ… RMSEæ”¹è¿›: {5.406580 - test_metrics['RMSE']:.6f}")
    
    # æ­¥éª¤7: å¯è§†åŒ–ç»“æžœ
    print("\næ­¥éª¤7: ä¿å­˜é¢„æµ‹ç»“æžœ")
    
    # æµ‹è¯•é›†ç»“æžœ
    plot_predictions_simple(y_test_true, y_test_pred, dates_test, 
                           "Improved Model - Test Set Predictions",
                           os.path.join(output_dir, 'improved_test_predictions.png'))
    
    print(f"\næ‰€æœ‰ç»“æžœå·²ä¿å­˜åˆ°: {output_dir}")
    print("=== æ”¹è¿›æ¨¡åž‹è®­ç»ƒå®Œæˆ! ===")
    
    return model, processor, trainer, test_metrics

if __name__ == "__main__":
    # è¿è¡Œæ”¹è¿›çš„è®­ç»ƒ
    print("ðŸš€ å¼€å§‹è®­ç»ƒæ”¹è¿›çš„LSTMæ¨¡åž‹...")
    model, processor, trainer, metrics = main_improved()